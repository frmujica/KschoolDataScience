{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vulnerability Hatstall\n",
    "\n",
    "![Categorization](figs/An-Illustrated-Guide-to-Categorizing-Yourself_HERO.png \"Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "*Objetivo: pretendo responder a una pregunta? Construir un modelo predictivo? En qu√© se parece/diferencia al state of the art? Hay algo similar hecho, y si es as√≠ en qu√© se diferencia lo que tengo pensado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "rise": {
     "theme": "sky"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objective\n",
    "\n",
    "Sorting vulnerabilites from different vulnerabilities scanners using a machine learning model.\n",
    "\n",
    "![objective](figs/hatstall_project.png \"hatstall_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "*Idea: Motivaci√≥n y overview general. ¬øPor qu√© me interesa el tema? ¬øQu√© conozco previamente? ¬øQu√© voy a hacer distinto de lo que existe? ¬øQu√© aporto?Aqu√≠ funciona muy bien que elij√°is un tema que conoc√©is bien y/o os afecta personalmente. Aficiones vuestras, campos de experiencia laboral, problemas que hay√°is visto a vuestro alrededor y a los que cre√°is que pod√©is aportar...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Currently there is a [dataset](https://www.kaggle.com/vsathiamoo/cve-common-vulnerabilities-and-exposures) in Kaggle and it compiles information about Common Vulnerabilities and Exposures(CVE) but that information normally comes in the tools plugins or databases and results, so it is not useful for our purposes. Also, there is a [kernel](https://www.kaggle.com/walterhaydock/cybersecurity-vulnerability-analysis-with-k-means) but they focus in vulnerabilities and our project want to focus on patching vulnerabilities.  \n",
    "\n",
    "Also, there are a lot of information about [vulnerability management](#References) however it is quite difficult to find information about how to do vulnerability management. Like many other topics there is not only one way to do vulnerability management nor the \"properly\" way to do it, so in this case we are going to implement the way we know it and it worked for us during long time. The steps we normally use are explained deeper in the [Reasons](#Reasons) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Mainly because We need it in our job. We have been working in a method to make vulnerability management easier.\n",
    "- Many companies work with a lot of vulnerabilities scanners, and this is the way to normalize the results for all of those tools.\n",
    "- We have never found anybody who works in something similar.\n",
    "- There are not many data-science projects about cybersecurity, just search in [kaggle](https://www.kaggle.com) \"cycbersecurity\" and you will found out.\n",
    "- It is a good way to practice data cleaning and wrangling and change our mind paradigm.\n",
    "- Because I want and I can üòú"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The main reason for working in this project is to make easier the vulnerability management. Many people thinks that it is simple as just as run a vulnerability scan and then just give a simple report to the responsible team for patching however there is nothing more wrong than that. Vulnerability management is very important activity to analyze those reports, one of those steps consist in **categorizing vulnerabilities in groups**, filter all the important one, then we have got to reduce false positives and group as much as possible the vulnerabilities that can be solved by the same patch to make the work easier for patching team. Probably, one of the most difficult job is to categorize all of those vulnerabilities, especially if you have got different tools that work and generate results in different ways.\n",
    "\n",
    "The scope of this project is only about categorizing vulnerabilities from [Openvas](http://www.openvas.org/) because the tool is open source and its data is open to public. this might be called the first \"subproject\" from a bigger one. Categorizing too many vulnerabilities could be an exhaustive work, especially if there come from many tools. \n",
    "\n",
    "Many people would think the scope of this project is quite short however we plan to go further and make this project much more elegant, in the future we want to implement this to other tools like [Qualys](https://www.qualys.com/) or [Insightvm](https://www.rapid7.com/products/insightvm/), we are also focusing only in \"plugins\" or \"knowledge database\" because we are not going to run any vulnerability scan and we do not have the resources and open data to do this, imagine that nobody who has common sense is going to public their vulnerabilities to Internet, that is going to make hackers' job easier. However our job is going to be useful because companies will be able to join their vulnerabilities results with the output we generated and they can enrich their results with the data we categorized. Also we plan to use analytics and/or other machine learning models that can suggest to patching team things like \"Close port 8900 on this servers and you will be less vulnerable to Elastic vulnerabilities\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "*Datos: de d√≥nde los voy a sacar, o c√≥mo los pienso generar? Los conozco ya? Los he explorado un poco? Si es creativo mucho mejor. No est√° prohibido coger un Kaggle y hacerlo, pero en mi experiencia suelen quedar TFMs muy muy pobres as√≠. La imaginaci√≥n es el l√≠mite*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "- We are going to work with official feeds from Openvas, data is public.\n",
    "\n",
    "![Data](figs/Data-Science-Image3.png \"Objetive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We are going to work with Openvas because it is free and open source scanner, data is available for public, and it can be downloaded from its [official web](http://dl.greenbone.net/community-nvt-feed-current.tar.bz2). \n",
    "\n",
    "Data is subdivided in different folders and sub-folders, I worked in a python Script in the past that used to go through those folders, read the different files, look for an unique id and categorize those vulnerabilities with regular expressions and string functions, apply a categorization and then write the output in a csv file. The current script works quite good but I strongly think a machine learning model would work much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "These are the categories I create with the current script: \n",
    "\n",
    "#### Useful categories for vulnerability management\n",
    "\n",
    "- Update or patch installation\n",
    "- End of life Platform\n",
    "- Informational\n",
    "- Workaround\n",
    "- No solution or patch available\n",
    "- Policy compliance\n",
    "- Insecure or useless service\n",
    "- Configuration changes\n",
    "- SSL/TLS hardening\n",
    "\n",
    "#### Categories that belongs only to Openvas but are not useful for vulnerability management.\n",
    "\n",
    "- To classify\n",
    "- GSHB Family\n",
    "- NMAP Family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Execution plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "*T√©cnicas de an√°lisis que voy a aplicar y resultado que espero obtener. Tecnolog√≠as que pienso usar.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The most difficult and tedious work is the cleaning, the data come from different files divided in many directories and subdirectories. We are going to follow those steps: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Download the files from the [Openvas](http://dl.greenbone.net/community-nvt-feed-current.tar.bz2) web.\n",
    "2. Transform the raw data in an structure data (JSON, CSV or SQL). We might spend 90% of the time here.\n",
    "3. Represent the [words in vectors](https://www.tensorflow.org/tutorials/representation/word2vec)\n",
    "4. Label the output with the categories showed in the [Data](#Data) section.\n",
    "5. Deal with \"oversampling\"\n",
    "6. Apply a supervised ML model (We don't know which one yet). (**REVISAR bien este punto**)\n",
    "7. Test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tools\n",
    "![Categorization](figs/ds_stack_tools-696x552.png \"Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Main Tools\n",
    "\n",
    "- Python as programming language. (**F\\*\\* \"R\"**)\n",
    "- Jupyter\n",
    "- Altair for visualizations\n",
    "- Machine Learning framework (Keras or Sklearn)\n",
    "\n",
    "## Contingency tools\n",
    "\n",
    "- Splunk for cleaning and visualization.\n",
    "- Gemsim for working with words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We plan to use python (**Fu\\*\\* \"R\"**) as programming language and other open source tools to commit our achievement. We also might use [Splunk](https://www.splunk.com) to speed the cleaning data work because we have been working with Splunk for years and we know how to use it perfectly, we might use it to make some operations that can be more difficult to do with pandas, however our priority are opensource tools.\n",
    "\n",
    "We might use [Gemsim](https://radimrehurek.com/gensim/index.html) to work in semantic words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "- http://www.lmgtfy.com/?q=vulnerability+management\n",
    "- https://whatis.techtarget.com/definition/Vulnerability_management\n",
    "- https://www.tripwire.com/state-of-security/vulnerability-management/what-is-vulnerability-management-anyway/\n",
    "- https://www.kaggle.com/vsathiamoo/cve-common-vulnerabilities-and-exposures\n",
    "- https://www.kaggle.com/walterhaydock/cybersecurity-vulnerability-analysis-with-k-means"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
